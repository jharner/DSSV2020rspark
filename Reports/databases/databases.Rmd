---
title: "Extracting Data from Databases for Plotting in R"
author: "Jim Harner"
date: "7/29/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(RPostgreSQL)
```

This report introduces relational data base management systems. The relational model is essential for multi-user transactional data.

Content in this section is based partly on material in Paul Murrell's [Introduction to Data Technologies](https://www.stat.auckland.ac.nz/~paul/ItDT/).

A *relational data base management system* (RDBMS) is based on Codd's *relational model* (RM), which in turn is based on *relational algebra*. It uses Structured Query Language (SQL) as a query language. 

A single logical operation on a database is called a *transaction*. A single transaction can involve multiple changes, e.g., debiting one account and crediting another when funds are transferred in a bank. To perform these operations safely, certain properties must be met.

RDBMS should maintain ACID properties:  

* Atomicity: transactions are all or nothing;  
* Consistency: transactions bring the database from one valid state to another;  
* Isolation: concurrent transactions maintain state as if they are serial transactions;  
* Durability; a committed transaction maintains state even if there are crashes, power failures, etc.  

We will be using PostgreSQL an open source DBMS that is stable and feature rich. PostgreSQL has a command-line interface for making queries called `psql`. 

We have several built in databases on our PostgreSQL container, including `dataexpo`.

The Data Expo data set consists of seven atmospheric measurements at locations on a 24 by 24 grid averaged over each month for six years (72 time points). The elevation (height above sea level) at each location is also included in the data set.

The table schema for `dataexpo` is defined as follows.
```
date_table ( ID [PK], date, month, year )

location_table ( ID [PK], longitude, latitude, elevation )

measure_table ( date [PK] [FK date_table.ID],
                location [PK] [FK location_table.ID],
                cloudhigh, cloudlow, cloudmid, ozone,
                pressure, surftemp, temperature )
```

We connect to PostgreSQL through the R package `RPostgreSQL`.
```{r}
drv <- dbDriver("PostgreSQL")
con <- dbConnect(drv, host = "rpsql", dbname = "dataexpo")
dbListTables(con)
dbListFields(con, "location_table")

# dbGetQuery returns a data.frame which can be used directly
meas <- dbGetQuery(con, "select * from location_table")
class(meas)
head(meas)
rm(meas)
```
We use `dbGetQuery` here to select all columns from the `location_table` and return the results in a data frame.

In principle, it would be possible to extract data from the tables of interest and use R functions to join as needed. However, this would be far less efficient than selecting directly from the database. The following example illustrates this.

Suppose we want to plot the average temperature (Kelvin) vs. the base elevation. First, we extract `surftemp` and then average and `elevation` grouped by multiples of 500. The required `select` statement involves joins, grouping, etc.
```{r}
temp.avgs <- dbGetQuery(con,
    "select round(l.elevation/500)*500 base_elev, avg(m.surftemp) avg_temp
    from measure_table m
    join location_table l on m.location = l.id 
    join date_table d on m.date = d.id
    where d.year = 1998 
    group by base_elev 
    order by base_elev")
temp.avgs

dbDisconnect(con)
dbUnloadDriver(drv)
```
I am assuming you have basic knowledge of `select`. We use `dbGetQuery` in order to get the data frame directly---in this case `temp.avgs`.

Now plot the data frame.
```{r}
plot(temp.avgs, type="l",
  xlab="Base Elevation (feet)", ylab="Average Temperature(Kelvin)",
  main=" Avg Temperature by Elevation")
```

As the base elevation increases, the average temperature tends to decrease as expected.
